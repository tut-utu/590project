{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy.io\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, RepeatVector, Activation, Bidirectional\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import ast\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicDataProvider: reading data/flickr8k/dataset.json\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'data/flickr8k/dataset.json'\n",
    "print('BasicDataProvider: reading %s' % (dataset_path, )) \n",
    "dataset = json.load(open(dataset_path, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('flickr8k_dataset.txt', 'w')\n",
    "f.write(\"filename\\timage_id\\tcaption_id\\tcaptions\\tsplit\\n\")\n",
    "a = []\n",
    "for i in dataset['images']:\n",
    "    for n,j in enumerate(i['sentids']):\n",
    "\n",
    "        f.write(i['filename']+ \"\\t\" + str(i['imgid']) + \"\\t\" + str(j) + \"\\t\" +\n",
    "         str(['<start>']+i['sentences'][n]['tokens']+['.'])+\"\\t\"+i['split']+ \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProBuildWordVocab(dataset='flickr8k', word_count_threshold=5):\n",
    "  # count up all word counts so that we can threshold\n",
    "  # this shouldnt be too expensive of an operation\n",
    "  print('preprocessing word counts and creating vocab based on word count threshold %d' % (word_count_threshold, ))\n",
    "  if dataset == 'flickr8k':\n",
    "      sentences = pd.read_csv('flickr8k_dataset.txt', delimiter='\\t')['captions'].to_list()\n",
    "  t0 = time.time()\n",
    "  word_counts = {}\n",
    "  nsents = 0\n",
    "  max_len = 0\n",
    "  for sent in sentences:\n",
    "    tokened = ast.literal_eval(sent)\n",
    "    if len(tokened) > max_len:\n",
    "      max_len = len(tokened)\n",
    "    nsents += 1\n",
    "    for w in tokened:\n",
    "      word_counts[w] = word_counts.get(w, 0) + 1\n",
    "  vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "  print('filtered words from %d to %d in %.2fs' % (len(word_counts), len(vocab), time.time() - t0))\n",
    "\n",
    "  ixtoword = {}\n",
    "  ixtoword[0] = '.'  # period at the end of the sentence. make first dimension be end token\n",
    "  wordtoix = {}\n",
    "  wordtoix['#START#'] = 0 # make first vector be the start token\n",
    "  ix = 1\n",
    "  for w in vocab:\n",
    "    wordtoix[w] = ix\n",
    "    ixtoword[ix] = w\n",
    "    ix += 1\n",
    "\n",
    "  # compute bias vector, which is related to the log probability of the distribution\n",
    "  # of the labels (words) and how often they occur. We will use this vector to initialize\n",
    "  # the decoder weights, so that the loss function doesnt show a huge increase in performance\n",
    "  # very quickly (which is just the network learning this anyway, for the most part). This makes\n",
    "  # the visualizations of the cost function nicer because it doesn't look like a hockey stick.\n",
    "  # for example on Flickr8K, doing this brings down initial perplexity from ~2500 to ~170.\n",
    "  # word_counts['.'] = nsents\n",
    "  # bias_init_vector = np.array([1.0*word_counts[ixtoword[i]] for i in ixtoword])\n",
    "  # bias_init_vector /= np.sum(bias_init_vector) # normalize to frequencies\n",
    "  # bias_init_vector = np.log(bias_init_vector)\n",
    "  # bias_init_vector -= np.max(bias_init_vector) # shift to nice numeric range\n",
    "  return wordtoix, ixtoword,max_len,len(wordtoix)#, bias_init_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing word counts and creating vocab based on word count threshold 5\n",
      "filtered words from 8385 to 2943 in 1.07s\n"
     ]
    }
   ],
   "source": [
    "wordtoix, ixtoword,max_len,voc_len = preProBuildWordVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(wordtoix,max_len,batch_size = 32):\n",
    "        captions = []\n",
    "        images = []\n",
    "\n",
    "        df = pd.read_csv('flickr8k_training_dataset.txt', delimiter='\\t')\n",
    "        df = df.sample(frac=1)\n",
    "        iter = df.iterrows()\n",
    "        c = []\n",
    "        imgs = []\n",
    "        for i in range(df.shape[0]):\n",
    "                x = next(iter)\n",
    "                c.append(ast.literal_eval(x[1][3]))\n",
    "                imgs.append(x[1][1])\n",
    "        features_path = 'data/flickr8k/vgg_feats.mat'\n",
    "        features_struct = scipy.io.loadmat(features_path)['feats']\n",
    "        count = 0\n",
    "        while True:\n",
    "            for text,im in zip(c,imgs):\n",
    "                current_image = features_struct[:,im]\n",
    "                word_idx = [wordtoix[i] for i in text if i in wordtoix]\n",
    "                word_idx.append(0)\n",
    "                captions.append(word_idx)\n",
    "                count+=1\n",
    "                images.append(current_image)\n",
    "                if count>=batch_size:\n",
    "                    images = np.asarray(images)\n",
    "                    captions = pad_sequences(captions, maxlen=max_len, padding='post')\n",
    "                    yield [[images, captions], captions]\n",
    "                    captions = []\n",
    "                    images = []\n",
    "                    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_generator(wordtoix,max_len,batch_size = 32)\n",
    "b = next(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_model = Sequential([\n",
    "#        Dense(256, input_shape=(max_len,), activation='relu'),\n",
    "#       RepeatVector(max_len)\n",
    "#       ])\n",
    "image_model = Sequential()\n",
    "image_model.add(Dense(256, input_shape=(4096,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "# caption_model = Sequential([\n",
    "#           Embedding(voc_len,256, input_length=max_len),\n",
    "#           LSTM(256, return_sequences=True)\n",
    "#                     ])\n",
    "caption_model = Sequential()\n",
    "caption_model.add(Embedding(max_len,256, input_length=max_len))\n",
    "caption_model.add(LSTM(256, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = Sequential([\n",
    "#                         Concatenate((image_model, caption_model)),\n",
    "#                         Bidirectional(LSTM(256, return_sequences=False)),\n",
    "#                         Dense(voc_len),\n",
    "#                         Activation('softmax')\n",
    "#                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_layer = concatenate([image_model.output, caption_model.output],axis=1)\n",
    "x = Bidirectional(LSTM(256, return_sequences=False))(concat_layer)\n",
    "x = Dense(max_len)(x)\n",
    "out = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Model([image_model.input, caption_model.input],[out])\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 2944])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model([b[0][0],b[0][1].astype('float32')]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit_generator(data_generator(wordtoix,max_len,batch_size = 256), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_input (InputLayer)       [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_input (InputLayer)   [(None, 39)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 39, 256)      9984        ['embedding_input[0][0]']        \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 39, 256)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 39, 256)      525312      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 78, 256)      0           ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 512)          1050624     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 39)           20007       ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 39)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,654,759\n",
      "Trainable params: 2,654,759\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing word counts and creating vocab based on word count threshold 5\n",
      "Length of the word index: 2944\n"
     ]
    }
   ],
   "source": [
    "from keras_version.model import keras_model\n",
    "from keras_version.data_generator import *\n",
    "\n",
    "dataset = 'flickr8k'\n",
    "word_count_threshold=5\n",
    "batch_size=256\n",
    "\n",
    "\n",
    "\n",
    "embedding_size=258\n",
    "input_size=4096\n",
    "activation='relu'\n",
    "\n",
    "metrics = ['Accuracy']\n",
    "loss='categorical_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "\n",
    "epochs=1\n",
    "\n",
    "\n",
    "checkpoint_filepath = r'./saved_model/checkpoint'\n",
    "data = data_generator(dataset=dataset)\n",
    "data.build_vocab(word_count_threshold=word_count_threshold)\n",
    "generatort = build_generator(data._wordtoix,data._max_len,batch_size,dataset)\n",
    "model = keras_model(data._max_len,embedding_size=embedding_size,input_size=input_size,activation=activation)\n",
    "model.load_weights(checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing word counts and creating vocab based on word count threshold 5\n",
      "Length of the word index: 2944\n"
     ]
    }
   ],
   "source": [
    "dataset = 'flickr8k'\n",
    "word_count_threshold=5\n",
    "batch_size=256\n",
    "\n",
    "\n",
    "\n",
    "embedding_size=256\n",
    "input_size=4096\n",
    "activation='relu'\n",
    "mode = 'new'\n",
    "metrics = ['Accuracy']\n",
    "loss='categorical_crossentropy'\n",
    "optimizer='Adam'\n",
    "checkpoint_filepath = r'./saved_model/checkpoint'\n",
    "\n",
    "\n",
    "epochs=1\n",
    "from keras_version.model import keras_model\n",
    "from keras_version.data_generator import *\n",
    "data = data_generator(dataset=dataset)\n",
    "data.build_vocab(word_count_threshold=word_count_threshold)\n",
    "generatort = build_generator(data._wordtoix,data._max_len,batch_size,dataset)\n",
    "model = keras_model(data._max_len,data._vocab_len,embedding_size=embedding_size,input_size=input_size,activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " dense_input (InputLayer)       [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_input (InputLayer)   [(None, 39)]         0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 39, 256)      753920      ['embedding_input[0][0]']        \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 39, 256)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 39, 256)      525312      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 78, 256)      0           ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 512)          1050624     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 39)           20007       ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 39)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,398,695\n",
      "Trainable params: 3,398,695\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('en3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f45f0d2f3d1f97bc4fb6554f2443b504785106d5f3612aa10fe5614abe2bf15d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
